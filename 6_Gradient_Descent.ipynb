{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Perceptron with Gradient Descent\n",
    "\n",
    "**Perceptron Function:** Receives Two Inputs, applying linear combination function as linear_combination = weight1 . input1 + weight2 . input2\n",
    "\n",
    "**Activation Function:** In this case, Sigmoid Function with Bias: output as range of probabilities (of success)\n",
    "\n",
    "**Error** Error is nothing but known output (y) minus computed output (y-hat)\n",
    "\n",
    "**Error Term** Error minus derivative of sigmoid\n",
    "\n",
    "**Gradient Descent Step** Gives us revised weights, or 'delta w' -- It is learning rate (eta) multipliedBy error_term  multipliedBy input(x)\n",
    "\n",
    "**Gradient Descent** After every step computed i.e. delta of weights. Updated weights with delta weights from Gradient Step. We will be follwing MSE (Mean Squared Error) instead of SSE (Sum of Squared Errors) avoid Gradient from Divergering & keep it computationally efficient .. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Train loss: ', 0.26415806826348665)\n",
      "('Train loss: ', 0.24218509921245185)\n",
      "('Train loss: ', 0.22867638598347267)\n",
      "('Train loss: ', 0.21975694986932126)\n",
      "('Train loss: ', 0.2137044846705392)\n",
      "('Train loss: ', 0.2095265703835622)\n",
      "('Train loss: ', 0.20658918287868835)\n",
      "('Train loss: ', 0.20448172801182843)\n",
      "('Train loss: ', 0.2029381856578586)\n",
      "('Train loss: ', 0.2017849943019407)\n",
      "Prediction accuracy: 0.750\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from data_prep import features, targets, features_test, targets_test\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Calculate sigmoid\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Use to same seed to make debugging easier\n",
    "np.random.seed(42)\n",
    "\n",
    "n_records, n_features = features.shape\n",
    "last_loss = None\n",
    "\n",
    "# Initialize weights\n",
    "weights = np.random.normal(scale=1/n_features**.5, size=n_features)\n",
    "\n",
    "# Neural Network parameters\n",
    "epochs = 10000\n",
    "learnrate = 0.01\n",
    "\n",
    "for e in range(epochs):\n",
    "    del_w = np.zeros(weights.shape)\n",
    "    for x, y in zip(features.values, targets):\n",
    "        # Loop through all records, x is the input, y is the target\n",
    "\n",
    "        # Activation of the output unit\n",
    "        output = sigmoid(np.dot(x, weights))\n",
    "\n",
    "        # The error, the target minues the network output\n",
    "        error = y - output\n",
    "\n",
    "        # The gradient descent step, the error times the gradient times the inputs\n",
    "        del_w += error * output * (1 - output) * x\n",
    "\n",
    "        # Update the weights here. The learning rate times the \n",
    "        # change in weights, divided by the number of records to average\n",
    "    weights += learnrate * del_w / n_records\n",
    "\n",
    "    # Printing out the mean square error on the training set\n",
    "    if e % (epochs / 10) == 0:\n",
    "        out = sigmoid(np.dot(features, weights))\n",
    "        loss = np.mean((out - targets) ** 2)\n",
    "        if last_loss and last_loss < loss:\n",
    "            print(\"Train loss: \", loss, \"  WARNING - Loss Increasing\")\n",
    "        else:\n",
    "            print(\"Train loss: \", loss)\n",
    "        last_loss = loss\n",
    "\n",
    "\n",
    "# Calculate accuracy on test data\n",
    "tes_out = sigmoid(np.dot(features_test, weights))\n",
    "predictions = tes_out > 0.5\n",
    "accuracy = np.mean(predictions == targets_test)\n",
    "print(\"Prediction accuracy: {:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
