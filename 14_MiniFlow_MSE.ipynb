{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created By: Anshoo Mehra\n",
    "\n",
    "### At this stage, we will start creating library called MiniFLow, which is like our own version of Tensorflow .. \n",
    "\n",
    "Class Architecture:\n",
    "\n",
    "--  **Neuron** [ Base Class ] <br>\n",
    "----  **Input** [ Sub-Class which is only used as Input Layer Node, i.e. performing no operation ]<br>\n",
    "----  **Add** [ Sub-Class which is only used as Hidden Layer Node. i.e. performing some operation ]<br>\n",
    "\n",
    "Each of above class has method name foward like Input.forward() or Add.foward() -- these are basically computing values which these are expected to foward, in case of Input it is simply placeholder.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fix the Sigmoid class so that it computes the sigmoid function\n",
    "on the forward pass!\n",
    "\n",
    "Scroll down to get started.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class Layer:\n",
    "    def __init__(self, inbound_layers=[]):\n",
    "        self.inbound_layers = inbound_layers\n",
    "        self.value = None\n",
    "        self.outbound_layers = []\n",
    "        for layer in inbound_layers:\n",
    "            layer.outbound_layers.append(self)\n",
    "\n",
    "    def forward():\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def backward():\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class Input(Layer):\n",
    "    def __init__(self):\n",
    "        # An Input layer has no inbound layers,\n",
    "        # so no need to pass anything to the Layer instantiator\n",
    "        Layer.__init__(self)\n",
    "\n",
    "    def forward(self):\n",
    "        # Do nothing because nothing is calculated.\n",
    "        pass\n",
    "\n",
    "    def backward(self):\n",
    "        # An Input Layer has no inputs so we refer to ourself\n",
    "        # for the gradient\n",
    "        self.gradients = {self: 0}\n",
    "        for n in self.outbound_Layers:\n",
    "            self.gradients[self] += n.gradients[self]\n",
    "\n",
    "\n",
    "class Linear(Layer):\n",
    "    def __init__(self, inbound_layer, weights, bias):\n",
    "        # Notice the ordering of the input layers passed to the\n",
    "        # Layer constructor.\n",
    "        Layer.__init__(self, [inbound_layer, weights, bias])\n",
    "\n",
    "    def forward(self):\n",
    "        inputs = self.inbound_layers[0].value\n",
    "        weights = self.inbound_layers[1].value\n",
    "        bias = self.inbound_layers[2].value\n",
    "        self.value = np.dot(inputs, weights) + bias\n",
    "        #print (\"Reaching here1'\", self.value)\n",
    "\n",
    "\n",
    "class Sigmoid(Layer):\n",
    "    \"\"\"\n",
    "    You need to fix the `_sigmoid` and `forward` methods.\n",
    "    \"\"\"\n",
    "    def __init__(self, layer):\n",
    "        Layer.__init__(self, [layer])\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        \"\"\"\n",
    "        This method is separate from `forward` because it\n",
    "        will be used with `backward` as well.\n",
    "\n",
    "        `x`: A numpy array-like object.\n",
    "\n",
    "        Return the result of the sigmoid function.\n",
    "        \n",
    "        Your code here!\n",
    "        \"\"\"\n",
    "        #print (\"Reaching here2'\", x)\n",
    "        sigmoid = 1 / (1 + np.exp(-x))\n",
    "        return sigmoid\n",
    "\n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "        Set the value of this layer to the result of the\n",
    "        sigmoid function, `_sigmoid`.\n",
    "        \n",
    "        Your code here!\n",
    "        \"\"\"\n",
    "        input_value = self.inbound_layers[0].value\n",
    "        self.value = self._sigmoid(input_value)\n",
    "\n",
    "class MSE(Layer):\n",
    "    def __init__(self, y, a):\n",
    "        \"\"\"\n",
    "        The mean squared error cost function.\n",
    "        Should be used as the last layer for a network.\n",
    "        \"\"\"\n",
    "        # Call the base class' constructor.\n",
    "        Layer.__init__(self, [y, a])\n",
    "\n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "        Calculates the mean squared error.\n",
    "        \"\"\"\n",
    "        # NOTE: We reshape these to avoid possible matrix/vector broadcast\n",
    "        # errors.\n",
    "        #\n",
    "        # For example, if we subtract an array of shape (3,) from an array of shape\n",
    "        # (3,1) we get an array of shape(3,3) as the result when we want\n",
    "        # an array of shape (3,1) instead.\n",
    "        #\n",
    "        # Making both arrays (3,1) insures the result is (3,1) and does\n",
    "        # an elementwise subtraction as expected.\n",
    "        y = self.inbound_layers[0].value.reshape(-1, 1)\n",
    "        a = self.inbound_layers[1].value.reshape(-1, 1)\n",
    "        # TODO: your code here\n",
    "        \"\"\"\n",
    "        print(y)\n",
    "        print(a)\n",
    "        print(np.subtract(y,a))\n",
    "        print(np.square(np.subtract(y,a)))\n",
    "        print(np.sum(np.square(np.subtract(y,a)))/len(a))\n",
    "        \"\"\"\n",
    "        self.value = np.sum(np.square(np.subtract(y,a))) / len(a)\n",
    "#         ##Alternatively we can use mean function \n",
    "#         diff = y - a\n",
    "#         self.value = np.mean(diff**2)\n",
    "\n",
    "def topological_sort(feed_dict):\n",
    "    \"\"\"\n",
    "    Sort the layers in topological order using Kahn's Algorithm.\n",
    "\n",
    "    `feed_dict`: A dictionary where the key is a `Input` Layer and the value is the respective value feed to that Layer.\n",
    "\n",
    "    Returns a list of sorted layers.\n",
    "    \"\"\"\n",
    "\n",
    "    input_layers = [n for n in feed_dict.keys()]\n",
    "\n",
    "    G = {}\n",
    "    layers = [n for n in input_layers]\n",
    "    while len(layers) > 0:\n",
    "        n = layers.pop(0)\n",
    "        if n not in G:\n",
    "            G[n] = {'in': set(), 'out': set()}\n",
    "        for m in n.outbound_layers:\n",
    "            if m not in G:\n",
    "                G[m] = {'in': set(), 'out': set()}\n",
    "            G[n]['out'].add(m)\n",
    "            G[m]['in'].add(n)\n",
    "            layers.append(m)\n",
    "\n",
    "    L = []\n",
    "    S = set(input_layers)\n",
    "    while len(S) > 0:\n",
    "        n = S.pop()\n",
    "\n",
    "        if isinstance(n, Input):\n",
    "            n.value = feed_dict[n]\n",
    "\n",
    "        L.append(n)\n",
    "        for m in n.outbound_layers:\n",
    "            G[n]['out'].remove(m)\n",
    "            G[m]['in'].remove(n)\n",
    "            # if no other incoming edges add to S\n",
    "            if len(G[m]['in']) == 0:\n",
    "                S.add(m)\n",
    "    return L\n",
    "\n",
    "\n",
    "def forward_pass(graph):\n",
    "    \"\"\"\n",
    "    Performs a forward pass through a list of sorted Layers.\n",
    "\n",
    "    Arguments:\n",
    "\n",
    "        `graph`: The result of calling `topological_sort`.\n",
    "    \"\"\"\n",
    "    # Forward pass\n",
    "    for n in graph:\n",
    "        n.forward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Neural Network performing Linear Combination + Sigmoid Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.4166666667\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test your MSE method with this script!\n",
    "\n",
    "No changes necessary, but feel free to play\n",
    "with this script to test your network.\n",
    "\"\"\"\n",
    "\n",
    "# import numpy as np\n",
    "# from miniflow import *\n",
    "\n",
    "y, a = Input(), Input()\n",
    "cost = MSE(y, a) \n",
    "\n",
    "y_ = np.array([1, 2, 3])\n",
    "a_ = np.array([4.5, 5, 10])\n",
    "\n",
    "feed_dict = {y: y_, a: a_}\n",
    "graph = topological_sort(feed_dict)\n",
    "# forward pass\n",
    "forward_pass(graph)\n",
    "\n",
    "\"\"\"\n",
    "Expected output\n",
    "\n",
    "23.4166666667\n",
    "\"\"\"\n",
    "print(cost.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
