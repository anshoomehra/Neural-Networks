{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created By: Anshoo Mehra\n",
    "\n",
    "### At this stage, we will start creating library called MiniFLow, which is like our own version of Tensorflow .. \n",
    "\n",
    "Class Architecture:\n",
    "\n",
    "--  **Neuron** [ Base Class ] <br>\n",
    "----  **Input** [ Sub-Class which is only used as Input Layer Node, i.e. performing no operation ]<br>\n",
    "----  **Add** [ Sub-Class which is only used as Hidden Layer Node. i.e. performing some operation ]<br>\n",
    "\n",
    "Each of above class has method name foward like Input.forward() or Add.foward() -- these are basically computing values which these are expected to foward, in case of Input it is simply placeholder.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Modify Linear#forward so that it linearly transforms\n",
    "input matrices, weights matrices and a bias vector to\n",
    "an output.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class Layer:\n",
    "    def __init__(self, inbound_layers=[]):\n",
    "        self.inbound_layers = inbound_layers\n",
    "        self.value = None\n",
    "        self.outbound_layers = []\n",
    "        for layer in inbound_layers:\n",
    "            layer.outbound_layers.append(self)\n",
    "\n",
    "    def forward():\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class Input(Layer):\n",
    "    \"\"\"\n",
    "    While it may be strange to consider an input a layer when\n",
    "    an input is only an individual node in a layer, for the sake\n",
    "    of simpler code we'll still use Layer as the base class.\n",
    "    \n",
    "    Think of Input as collating many individual input nodes into\n",
    "    a Layer.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # An Input layer has no inbound layers,\n",
    "        # so no need to pass anything to the Layer instantiator\n",
    "        Layer.__init__(self)\n",
    "\n",
    "    def forward(self):\n",
    "        # Do nothing because nothing is calculated.\n",
    "        pass\n",
    "\n",
    "\n",
    "class Linear(Layer):\n",
    "    def __init__(self, inbound_layer, weights, bias):\n",
    "        # Notice the ordering of the input layers passed to the\n",
    "        # Layer constructor.\n",
    "        self.inbound_layer = inbound_layer\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "        Layer.__init__(self, [inbound_layer, weights, bias])\n",
    "\n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "        Set the value of this layer to the linear transform output.\n",
    "        \n",
    "        Your code goes here!\n",
    "        \"\"\"\n",
    "        #print(\"Akki\", self.inbound_layer.value)\n",
    "        #print(\"Akki1\", self.weights.value)\n",
    "        #print(\"Akki2\", self.bias.value)\n",
    "        self.value = np.dot(self.inbound_layer.value , self.weights.value) + self.bias.value\n",
    "\n",
    "#Alternatively Linear can be defined as \n",
    "# class Linear(Node):\n",
    "#     def __init__(self, X, W, b):\n",
    "#         # Notice the ordering of the inputs passed to the\n",
    "#         # Node constructor.\n",
    "#         Node.__init__(self, [X, W, b])\n",
    "\n",
    "#     def forward(self):\n",
    "#         X = self.inbound_nodes[0].value\n",
    "#         W = self.inbound_nodes[1].value\n",
    "#         b = self.inbound_nodes[2].value\n",
    "#         self.value = np.dot(X, W) + b\n",
    "        \n",
    "def topological_sort(feed_dict):\n",
    "    \"\"\"\n",
    "    Sort the layers in topological order using Kahn's Algorithm.\n",
    "\n",
    "    `feed_dict`: A dictionary where the key is a `Input` Layer and the value is the respective value feed to that Layer.\n",
    "\n",
    "    Returns a list of sorted layers.\n",
    "    \"\"\"\n",
    "\n",
    "    input_layers = [n for n in feed_dict.keys()]\n",
    "\n",
    "    G = {}\n",
    "    layers = [n for n in input_layers]\n",
    "    while len(layers) > 0:\n",
    "        n = layers.pop(0)\n",
    "        if n not in G:\n",
    "            G[n] = {'in': set(), 'out': set()}\n",
    "        for m in n.outbound_layers:\n",
    "            if m not in G:\n",
    "                G[m] = {'in': set(), 'out': set()}\n",
    "            G[n]['out'].add(m)\n",
    "            G[m]['in'].add(n)\n",
    "            layers.append(m)\n",
    "\n",
    "    L = []\n",
    "    S = set(input_layers)\n",
    "    while len(S) > 0:\n",
    "        n = S.pop()\n",
    "\n",
    "        if isinstance(n, Input):\n",
    "            n.value = feed_dict[n]\n",
    "\n",
    "        L.append(n)\n",
    "        for m in n.outbound_layers:\n",
    "            G[n]['out'].remove(m)\n",
    "            G[m]['in'].remove(n)\n",
    "            # if no other incoming edges add to S\n",
    "            if len(G[m]['in']) == 0:\n",
    "                S.add(m)\n",
    "    return L\n",
    "\n",
    "\n",
    "def forward_pass(output_layer, sorted_layers):\n",
    "    \"\"\"\n",
    "    Performs a forward pass through a list of sorted Layers.\n",
    "\n",
    "    Arguments:\n",
    "\n",
    "        `output_layer`: A Layer in the graph, should be the output layer (have no outgoing edges).\n",
    "        `sorted_layers`: a topologically sorted list of layers.\n",
    "\n",
    "    Returns the output layer's value\n",
    "    \"\"\"\n",
    "\n",
    "    for n in sorted_layers:\n",
    "        n.forward()\n",
    "\n",
    "    return output_layer.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Neural Network performing Linear Combination Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-9.  4.]\n",
      " [-9.  4.]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This scripts demonstrates how the new MiniFlow works!\n",
    "\n",
    "Update the Linear class in miniflow.py to work with\n",
    "numpy vectors (arrays) and matrices.\n",
    "\n",
    "Test your code here!\n",
    "\"\"\"\n",
    "\n",
    "#import numpy as np\n",
    "#from miniflow import *\n",
    "\n",
    "inputs, weights, bias = Input(), Input(), Input()\n",
    "\n",
    "f = Linear(inputs, weights, bias)\n",
    "\n",
    "x = np.array([[-1., -2.], [-1, -2]])\n",
    "w = np.array([[2., -3], [2., -3]])\n",
    "b = np.array([-3., -5])\n",
    "\n",
    "feed_dict = {inputs: x, weights: w, bias: b}\n",
    "\n",
    "graph = topological_sort(feed_dict)\n",
    "output = forward_pass(f, graph)\n",
    "\n",
    "\"\"\"\n",
    "Output should be:\n",
    "[[-9., 4.],\n",
    "[-9., 4.]]\n",
    "\"\"\"\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
