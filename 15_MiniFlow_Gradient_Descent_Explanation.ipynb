{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created By: Anshoo Mehra\n",
    "\n",
    "### At this stage, we will start creating library called MiniFLow, which is like our own version of Tensorflow .. \n",
    "\n",
    "Class Architecture:\n",
    "\n",
    "--  **Neuron** [ Base Class ] <br>\n",
    "----  **Input** [ Sub-Class which is only used as Input Layer Node, i.e. performing no operation ]<br>\n",
    "----  **Add** [ Sub-Class which is only used as Hidden Layer Node. i.e. performing some operation ]<br>\n",
    "\n",
    "Each of above class has method name foward like Input.forward() or Add.foward() -- these are basically computing values which these are expected to foward, in case of Input it is simply placeholder.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gradient_descent_update(x, gradx, learning_rate):\n",
    "    \"\"\"\n",
    "    Performs a gradient descent update.\n",
    "    \"\"\"\n",
    "    # TODO: Implement gradient descent.\n",
    "    \n",
    "    # Return the new value for x\n",
    "    x = x - learning_rate * gradx\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0: Cost = 4813641.000, x = 2194.000, gdx = 4388.000\n",
      "EPOCH 1: Cost = 3080732.040, x = 1755.200, gdx = 3510.400\n",
      "EPOCH 2: Cost = 1971670.306, x = 1404.160, gdx = 2808.320\n",
      "EPOCH 3: Cost = 1261870.796, x = 1123.328, gdx = 2246.656\n",
      "EPOCH 4: Cost = 807599.109, x = 898.662, gdx = 1797.325\n",
      "EPOCH 5: Cost = 516865.230, x = 718.930, gdx = 1437.860\n",
      "EPOCH 6: Cost = 330795.547, x = 575.144, gdx = 1150.288\n",
      "EPOCH 7: Cost = 211710.950, x = 460.115, gdx = 920.230\n",
      "EPOCH 8: Cost = 135496.808, x = 368.092, gdx = 736.184\n",
      "EPOCH 9: Cost = 86719.757, x = 294.474, gdx = 588.947\n",
      "EPOCH 10: Cost = 55502.445, x = 235.579, gdx = 471.158\n",
      "EPOCH 11: Cost = 35523.365, x = 188.463, gdx = 376.926\n",
      "EPOCH 12: Cost = 22736.753, x = 150.771, gdx = 301.541\n",
      "EPOCH 13: Cost = 14553.322, x = 120.616, gdx = 241.233\n",
      "EPOCH 14: Cost = 9315.926, x = 96.493, gdx = 192.986\n",
      "EPOCH 15: Cost = 5963.993, x = 77.195, gdx = 154.389\n",
      "EPOCH 16: Cost = 3818.755, x = 61.756, gdx = 123.511\n",
      "EPOCH 17: Cost = 2445.803, x = 49.404, gdx = 98.809\n",
      "EPOCH 18: Cost = 1567.114, x = 39.524, gdx = 79.047\n",
      "EPOCH 19: Cost = 1004.753, x = 31.619, gdx = 63.238\n",
      "EPOCH 20: Cost = 644.842, x = 25.295, gdx = 50.590\n",
      "EPOCH 21: Cost = 414.499, x = 20.236, gdx = 40.472\n",
      "EPOCH 22: Cost = 267.079, x = 16.189, gdx = 32.378\n",
      "EPOCH 23: Cost = 172.731, x = 12.951, gdx = 25.902\n",
      "EPOCH 24: Cost = 112.348, x = 10.361, gdx = 20.722\n",
      "EPOCH 25: Cost = 73.703, x = 8.289, gdx = 16.577\n",
      "EPOCH 26: Cost = 48.970, x = 6.631, gdx = 13.262\n",
      "EPOCH 27: Cost = 33.141, x = 5.305, gdx = 10.610\n",
      "EPOCH 28: Cost = 23.010, x = 4.244, gdx = 8.488\n",
      "EPOCH 29: Cost = 16.526, x = 3.395, gdx = 6.790\n",
      "EPOCH 30: Cost = 12.377, x = 2.716, gdx = 5.432\n",
      "EPOCH 31: Cost = 9.721, x = 2.173, gdx = 4.346\n",
      "EPOCH 32: Cost = 8.022, x = 1.738, gdx = 3.477\n",
      "EPOCH 33: Cost = 6.934, x = 1.391, gdx = 2.781\n",
      "EPOCH 34: Cost = 6.238, x = 1.112, gdx = 2.225\n",
      "EPOCH 35: Cost = 5.792, x = 0.890, gdx = 1.780\n",
      "EPOCH 36: Cost = 5.507, x = 0.712, gdx = 1.424\n",
      "EPOCH 37: Cost = 5.324, x = 0.570, gdx = 1.139\n",
      "EPOCH 38: Cost = 5.208, x = 0.456, gdx = 0.911\n",
      "EPOCH 39: Cost = 5.133, x = 0.365, gdx = 0.729\n",
      "EPOCH 40: Cost = 5.085, x = 0.292, gdx = 0.583\n",
      "EPOCH 41: Cost = 5.054, x = 0.233, gdx = 0.467\n",
      "EPOCH 42: Cost = 5.035, x = 0.187, gdx = 0.373\n",
      "EPOCH 43: Cost = 5.022, x = 0.149, gdx = 0.299\n",
      "EPOCH 44: Cost = 5.014, x = 0.119, gdx = 0.239\n",
      "EPOCH 45: Cost = 5.009, x = 0.096, gdx = 0.191\n",
      "EPOCH 46: Cost = 5.006, x = 0.076, gdx = 0.153\n",
      "EPOCH 47: Cost = 5.004, x = 0.061, gdx = 0.122\n",
      "EPOCH 48: Cost = 5.002, x = 0.049, gdx = 0.098\n",
      "EPOCH 49: Cost = 5.002, x = 0.039, gdx = 0.078\n",
      "EPOCH 50: Cost = 5.001, x = 0.031, gdx = 0.063\n",
      "EPOCH 51: Cost = 5.001, x = 0.025, gdx = 0.050\n",
      "EPOCH 52: Cost = 5.000, x = 0.020, gdx = 0.040\n",
      "EPOCH 53: Cost = 5.000, x = 0.016, gdx = 0.032\n",
      "EPOCH 54: Cost = 5.000, x = 0.013, gdx = 0.026\n",
      "EPOCH 55: Cost = 5.000, x = 0.010, gdx = 0.021\n",
      "EPOCH 56: Cost = 5.000, x = 0.008, gdx = 0.016\n",
      "EPOCH 57: Cost = 5.000, x = 0.007, gdx = 0.013\n",
      "EPOCH 58: Cost = 5.000, x = 0.005, gdx = 0.011\n",
      "EPOCH 59: Cost = 5.000, x = 0.004, gdx = 0.008\n",
      "EPOCH 60: Cost = 5.000, x = 0.003, gdx = 0.007\n",
      "EPOCH 61: Cost = 5.000, x = 0.003, gdx = 0.005\n",
      "EPOCH 62: Cost = 5.000, x = 0.002, gdx = 0.004\n",
      "EPOCH 63: Cost = 5.000, x = 0.002, gdx = 0.003\n",
      "EPOCH 64: Cost = 5.000, x = 0.001, gdx = 0.003\n",
      "EPOCH 65: Cost = 5.000, x = 0.001, gdx = 0.002\n",
      "EPOCH 66: Cost = 5.000, x = 0.001, gdx = 0.002\n",
      "EPOCH 67: Cost = 5.000, x = 0.001, gdx = 0.001\n",
      "EPOCH 68: Cost = 5.000, x = 0.001, gdx = 0.001\n",
      "EPOCH 69: Cost = 5.000, x = 0.000, gdx = 0.001\n",
      "EPOCH 70: Cost = 5.000, x = 0.000, gdx = 0.001\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Given the starting point of any `x` gradient descent\n",
    "should be able to find the minimum value of x for the\n",
    "cost function `f` defined below.\n",
    "\"\"\"\n",
    "# import random\n",
    "# from gd import gradient_descent_update\n",
    "\n",
    "\n",
    "def f(x):\n",
    "    \"\"\"\n",
    "    Quadratic function.\n",
    "\n",
    "    It's easy to see the minimum value of the function\n",
    "    is 5 when is x=0.\n",
    "    \"\"\"\n",
    "    return x**2 + 5\n",
    "\n",
    "\n",
    "def df(x):\n",
    "    \"\"\"\n",
    "    Derivative of `f` with respect to `x`.\n",
    "    \"\"\"\n",
    "    return 2*x\n",
    "\n",
    "\n",
    "# Random number better 0 and 10,000. Feel free to set x whatever you like.\n",
    "x = random.randint(0, 10000)\n",
    "# TODO: Set the learning rate\n",
    "learning_rate = 0.1\n",
    "epochs = 70\n",
    "\n",
    "for i in range(epochs+1):\n",
    "    cost = f(x)\n",
    "    gradx = df(x)\n",
    "    print(\"EPOCH {}: Cost = {:.3f}, x = {:.3f}, gdx = {:.3f}\".format(i, cost, x, gradx))\n",
    "    x = gradient_descent_update(x, gradx, learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
