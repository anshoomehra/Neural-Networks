{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created By: Anshoo Mehra\n",
    "\n",
    "### At this stage, we will start creating library called MiniFLow, which is like our own version of Tensorflow .. \n",
    "\n",
    "Class Architecture:\n",
    "\n",
    "--  **Neuron** [ Base Class ] <br>\n",
    "----  **Input** [ Sub-Class which is only used as Input Layer Node, i.e. performing no operation ]<br>\n",
    "----  **Add** [ Sub-Class which is only used as Hidden Layer Node. i.e. performing some operation ]<br>\n",
    "\n",
    "Each of above class has method name foward like Input.forward() or Add.foward() -- these are basically computing values which these are expected to foward, in case of Input it is simply placeholder.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNo need to change anything below here!\\n'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "You need to change the Add() class below.\n",
    "\"\"\"\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, inbound_neurons=[]):\n",
    "        # Neurons from which this Node receives values\n",
    "        self.inbound_neurons = inbound_neurons\n",
    "        # Neurons to which this Node passes values\n",
    "        self.outbound_neurons = []\n",
    "        # A calculated value\n",
    "        self.value = None\n",
    "        # Add this node as an outbound node on its inputs.\n",
    "        for n in self.inbound_neurons:\n",
    "            n.outbound_neurons.append(self)\n",
    "        \n",
    "\n",
    "    # These will be implemented in a subclass.\n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "        Forward propagation.\n",
    "\n",
    "        Compute the output value based on `inbound_neurons` and\n",
    "        store the result in self.value.\n",
    "        \"\"\"\n",
    "        raise NotImplemented\n",
    "\n",
    "\n",
    "class Input(Neuron):\n",
    "    def __init__(self):\n",
    "        # an Input neuron has no inbound nodes,\n",
    "        # so no need to pass anything to the Node instantiator\n",
    "        Neuron.__init__(self)\n",
    "        print (\"*****Instantiated Input Neuron!!\")\n",
    "\n",
    "    # NOTE: Input node is the only node where the value\n",
    "    # is passed as an argument to forward().\n",
    "    #\n",
    "    # All other neuron implementations should get the value\n",
    "    # of the previous neurons from self.inbound_neurons\n",
    "    #\n",
    "    # Example:\n",
    "    # val0 = self.inbound_neurons[0].value\n",
    "    def forward(self, value=None):\n",
    "        # Overwrite the value if one is passed in.\n",
    "        if value is not None:\n",
    "            self.value = value\n",
    "        print (\"***Forward Method of Input Instance Called with Value: \", self.value)\n",
    "\n",
    "\n",
    "class Add(Neuron):\n",
    "    def __init__(self, x, y):\n",
    "        # You could access `x` and `y` in forward with\n",
    "        # self.inbound_neurons[0] (`x`) and self.inbound_neurons[1] (`y`)\n",
    "        Neuron.__init__(self, [x, y])\n",
    "        print (\"*****Instantiated ADD Neuron!!\")\n",
    "\n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "        Set the value of this neuron (`self.value`) to the sum of it's inbound_nodes.\n",
    "        \n",
    "        Your code here!\n",
    "        \"\"\"\n",
    "        x_val= self.inbound_neurons[0].value\n",
    "        y_val= self.inbound_neurons[1].value\n",
    "        self.value = x_val+y_val\n",
    "        #print(\"xval, yval\", x_val, y_val)\n",
    "        print (\"***Forward Method of Add Instance Called with Value: \", self.value)\n",
    "\n",
    "\"\"\"\n",
    "No need to change anything below here!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Sort generic nodes in topological order using Kahn's Algorithm.\n",
    "from pprint import pprint\n",
    "def topological_sort(feed_dict):\n",
    "    \"\"\"\n",
    "    Sort generic nodes in topological order using Kahn's Algorithm.\n",
    "\n",
    "    `feed_dict`: A dictionary where the key is a `Input` node and the value is the respective value feed to that node.\n",
    "\n",
    "    Returns a list of sorted nodes.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"***Inside Topological Sort..\")\n",
    "    ## In this example, it should return pointers to Input Neurons i.e. X & Y\n",
    "    input_neurons = [n for n in feed_dict.keys()]\n",
    "    \n",
    "    ##Custom Data Structure, for ever Node, it holds Input and Output Nodes..\n",
    "    G = {}\n",
    "    ## This is just another copy of Input Neurons, Mutable, and will be changed in while loop below to add new\n",
    "    ## instance of Neurons example outbound infered from inbound..\n",
    "    neurons = [n for n in input_neurons]\n",
    "\n",
    "    ## For all Neurons, check then one by one if they exist in G, if not, add them..\n",
    "    i = 0 \n",
    "    while len(neurons) > 0:\n",
    "        i = i+1\n",
    "        n = neurons.pop(0)\n",
    "        ## If Instance of Neuron not in G, create with empty placeholder as set() which is unordered, unique by nature. \n",
    "        if n not in G:\n",
    "            G[n] = {'in': set(), 'out': set()}\n",
    "        ## For every instance of Neuron, look for outbound Neurons, remember instance of ADD will set itself as outbound\n",
    "        ## to X & Y ..\n",
    "        for m in n.outbound_neurons:\n",
    "            ## If Instance of Neuron not in G, create with empty placeholder as set() which is unordered, unique by nature. \n",
    "            if m not in G:\n",
    "                G[m] = {'in': set(), 'out': set()}\n",
    "            ## At this stage,\n",
    "            #### For G entry of Neuron (Input), set outbound Neuron\n",
    "            G[n]['out'].add(m)\n",
    "            #### For G entry of Neuron (Output), set inbound Neuron\n",
    "            G[m]['in'].add(n)\n",
    "            #### Add Identified Outbound Neuron to the existing list of Neurons, pretty cool as while loop expands\n",
    "            #### counter & implicitly process newly added nodes (magic of while loop)..\n",
    "            #### So if you were wondering how ADD Node gets to the list, the magic is sort of started to happen here .. \n",
    "            neurons.append(m)\n",
    "\n",
    "    print(\"\")\n",
    "    print (\"***Cryptic to read, but sort of readable, instance of G with values .. \")\n",
    "    print(\"\")\n",
    "    pprint (G)\n",
    "    print(\"\")\n",
    "    print(\"****Did you notice how the list of Neurons (which started with only Input Neurons), now smartly see ADD Node(Neuron) in the list, read comments in code to see how..****\")\n",
    "    print(\"\")\n",
    "    print(\"***Time to compute Topological Sort..\")\n",
    "    print(\"\")\n",
    "    \n",
    "    ##Placeholder for Sorted Neurons ..\n",
    "    L = []\n",
    "    ##Input Neurons ONLY with set() applied to filter non-unique instances if any .. \n",
    "    S = set(input_neurons)\n",
    "    \n",
    "    ## For every insatnce of Input Neuron..\n",
    "    while len(S) > 0:\n",
    "        #Create temporary reference for Input Neuron.. \n",
    "        n = S.pop()\n",
    "        ##Assert if indeed instance is of Class Input, if so, set value from what has been fed in Feed Dictionary ..\n",
    "        if isinstance(n, Input):\n",
    "            n.value = feed_dict[n]\n",
    "        ## Add Instance of Input Neuron to L, this also means it is dependency free and can be\n",
    "        ## complied / processed trouble free when executed.. \n",
    "        L.append(n)\n",
    "        \n",
    "        ##Below is hard to understand, since we already added 'n' to 'L'\n",
    "        ### Remove inbound & outbound entries from G List, you will see why G list, as once G List 'm' ie outbound\n",
    "        ### node no further inbound nodes len(G[m]['in']) == 0 -- m get added to the S list as last node,\n",
    "        ### In a way gets sorted to be last node in L for any computation we use this L list for .. \n",
    "        for m in n.outbound_neurons:\n",
    "            G[n]['out'].remove(m)\n",
    "            G[m]['in'].remove(n)\n",
    "            # if no other incoming edges add to S\n",
    "            #### So if you were wondering how ADD Node gets to the list, the magic is sort of happening here ..\n",
    "            #### See above comments, how smartly G list is created to help this process step .. \n",
    "            if len(G[m]['in']) == 0:\n",
    "                S.add(m)\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"***Topological Sort List..\")\n",
    "    print(\"\")  \n",
    "    pprint (L)\n",
    "    print(\"\")\n",
    "    print(\"***Completed Topological Sort..\")\n",
    "    print(\"\")\n",
    "    return L\n",
    "\n",
    "\n",
    "##Performs a forward pass through a list of sorted neurons.\n",
    "def forward_pass(output_neuron, sorted_neurons):\n",
    "    \"\"\"\n",
    "    Performs a forward pass through a list of sorted neurons.\n",
    "\n",
    "    Arguments:\n",
    "\n",
    "        `output_neuron`: A neuron in the graph, should be the output neuron (have no outgoing edges).\n",
    "        `sorted_neurons`: a topologically sorted list of neurons.\n",
    "\n",
    "    Returns the output neuron's value\n",
    "    \"\"\"\n",
    "    print(\"*****Inside Foward Pass..\")\n",
    "    for n in sorted_neurons:\n",
    "        n.forward()\n",
    "    print(\"*****Foward Pass Completed..\")\n",
    "    print(\"\")\n",
    "    \n",
    "    return output_neuron.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Implement Neural Nerowrk using above defined library called Miniflow .. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Instantiating Inbound Nodes X & Y\n",
      "*****Instantiated Input Neuron!!\n",
      "*****Instantiated Input Neuron!!\n",
      "\n",
      "Before Instantiating Output Node 'Add' \n",
      "*****Instantiated ADD Neuron!!\n",
      "\n",
      "\n",
      "***Inside Topological Sort..\n",
      "\n",
      "***Cryptic to read, but sort of readable, instance of G with values .. \n",
      "\n",
      "{<__main__.Input instance at 0x106087320>: {'in': set([]),\n",
      "                                            'out': set([<__main__.Add instance at 0x106159950>])},\n",
      " <__main__.Add instance at 0x106159950>: {'in': set([<__main__.Input instance at 0x106087320>,\n",
      "                                                     <__main__.Input instance at 0x106159e60>]),\n",
      "                                          'out': set([])},\n",
      " <__main__.Input instance at 0x106159e60>: {'in': set([]),\n",
      "                                            'out': set([<__main__.Add instance at 0x106159950>])}}\n",
      "\n",
      "****Did you notice how the list of Neurons (which started with only Input Neurons), now smartly see ADD Node(Neuron) in the list, read comments in code to see how..****\n",
      "\n",
      "***Time to compute Topological Sort..\n",
      "\n",
      "\n",
      "***Topological Sort List..\n",
      "\n",
      "[<__main__.Input instance at 0x106087320>,\n",
      " <__main__.Input instance at 0x106159e60>,\n",
      " <__main__.Add instance at 0x106159950>]\n",
      "\n",
      "***Completed Topological Sort..\n",
      "\n",
      "*****Inside Foward Pass..\n",
      "('***Forward Method of Input Instance Called with Value: ', 5)\n",
      "('***Forward Method of Input Instance Called with Value: ', 10)\n",
      "('***Forward Method of Add Instance Called with Value: ', 15)\n",
      "*****Foward Pass Completed..\n",
      "\n",
      "10 + 5 = 15 (according to miniflow)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script builds and runs a graph with miniflow.\n",
    "\n",
    "There is no need to change anything to solve this quiz!\n",
    "\n",
    "However, feel free to play with the network! Can you also\n",
    "build a network that solves the equation below?\n",
    "\n",
    "(x + y) + y\n",
    "\"\"\"\n",
    "# use this import when defined as py files\n",
    "#from miniflow import *\n",
    "\n",
    "print (\"Before Instantiating Inbound Nodes X & Y\")\n",
    "x, y = Input(), Input()\n",
    "print(\"\")\n",
    "\n",
    "print (\"Before Instantiating Output Node 'Add' \")\n",
    "f = Add(x, y)\n",
    "print(\"\")\n",
    "\n",
    "feed_dict = {x: 10, y: 5}\n",
    "\n",
    "sorted_neurons = topological_sort(feed_dict)\n",
    "output = forward_pass(f, sorted_neurons)\n",
    "\n",
    "# NOTE: because topological_sort set the values for the `Input` neurons we could also access\n",
    "# the value for x with x.value (same goes for y).\n",
    "print(\"{} + {} = {} (according to miniflow)\".format(feed_dict[x], feed_dict[y], output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
